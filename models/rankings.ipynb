{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymcdm.methods import TOPSIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Safety Model - TOPSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv('/Users/matthewvchou/ai-and-society-housing-finder/datasets/final.csv') # Input full path from own device\n",
    "\n",
    "# Separating into Safety (Crime) and Livability (Food)\n",
    "safety_cols = ['9', 'F', 'I', 'M', 'V']\n",
    "X_safety = full_dataset[safety_cols].values\n",
    "\n",
    "# Weights for Different Columns/Features\n",
    "# From most severe to least severe --> F (Felony), M (Misdemeanor), V (Violation), I (Infraction), 9 (Misc.)\n",
    "# Got these weights by asking ChatGPT\n",
    "safety_weights = np.array([0.1071, 0.4464, 0.0893, 0.2232, 0.1339])\n",
    "\n",
    "# Need to set each Column/Feature as a Net Negative\n",
    "# We used the counts of each crime type, so technically a higher number means less safe\n",
    "# We standardized the data, so no need to redo that part\n",
    "safety_criteria = np.array([-1, -1, -1, -1, -1])\n",
    "\n",
    "# Apply TOPSIS\n",
    "safety_topsis = TOPSIS()\n",
    "safety_scores = safety_topsis(X_safety, safety_weights, safety_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Livability Model - TOPSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating into Safety (Crime) and Livability (Food)\n",
    "livability_cols = ['A', 'AB', 'ABC', 'ABCD', 'ABCDK', 'ABCH', 'ABCHDK', 'ABCHK', 'ABCK', 'ABH' , 'ABHK', 'ABK', 'AC', 'ACD', 'ACDK', 'ACE', 'ACED', 'ACEDK', 'ACEWD', 'ACH', 'ACHD', 'ACHDK', 'ACHK', 'ACK', 'AD', 'ADK', 'AEHK', 'AHDK', 'AM']\n",
    "X_livability = full_dataset[livability_cols].values\n",
    "\n",
    "\n",
    "# Weights for Different Columns/Features\n",
    "# Base Values generated by ChatGPT (based on how beneficial/comprehensive the store type is to residents)\n",
    "# Will generate weights for each column based on the sum of its parts\n",
    "\n",
    "# A (Store) = 1.0\n",
    "# B (Bakery) = 0.5\n",
    "# C (Food Manufacturer) = 0.3\n",
    "# D (Food Warehouse) = 0.4\n",
    "# E (Beverage Plant) = 0.3\n",
    "# H (Wholesale Manufacturer) = 0.4\n",
    "# K (Vehicle) = 0.2\n",
    "# M (Salvage Dealer) = 0.1\n",
    "# W (Farm Winery) = 0.3\n",
    "# TOTAL = 3.5\n",
    "\n",
    "# Go to file below to see what each code means:\n",
    "# /datasets/details/livability/NYSDAM_RetailFoodStoresEstablishmentTypeCodes.pdf\n",
    "gpt_base = {'A': 1,\n",
    "            'B': 0.5,\n",
    "            'C': 0.3,\n",
    "            'D': 0.4,\n",
    "            'E': 0.3,\n",
    "            'H': 0.4,\n",
    "            'K': 0.2,\n",
    "            'M': 0.1,\n",
    "            'W': 0.3}\n",
    "\n",
    "livability_weights = np.array([])\n",
    "\n",
    "# Sum the base values for each letter in label, divide by total\n",
    "for col in livability_cols:\n",
    "    total = 0\n",
    "    for char in col:\n",
    "        total += gpt_base[char]\n",
    "    livability_weights = np.append(livability_weights, total / 3.5)\n",
    "    total = 0\n",
    "\n",
    "# Normalizing weights\n",
    "livability_weights = livability_weights / livability_weights.sum()\n",
    "\n",
    "# Need to set each Column/Feature as a Net Positive\n",
    "# We used the counts of each establishment type, so a higher number means more livable/more stores (intuitively)\n",
    "# We standardized the data, so no need to redo that part\n",
    "livability_criteria = np.array([1] * len(livability_cols))\n",
    "\n",
    "# Apply TOPSIS\n",
    "livability_topsis = TOPSIS()\n",
    "livability_scores = livability_topsis(X_livability, livability_weights, livability_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Rankings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     zipcodes  safety_scores  livability_scores  safety_rank  livability_rank\n",
      "0       10001       0.469868           0.032807          161              127\n",
      "1       10002       0.568915           0.253458          150               11\n",
      "2       10003       0.600983           0.045683          143              112\n",
      "3       10004       0.968906           0.004491           24              169\n",
      "4       10005       0.989290           0.003925           10              170\n",
      "..        ...            ...                ...          ...              ...\n",
      "172     11691       0.599550           0.034662          144              125\n",
      "173     11692       0.897183           0.014967           61              157\n",
      "174     11693       0.847475           0.035749           83              123\n",
      "175     11694       0.954065           0.018019           32              153\n",
      "176     11697       0.999535           0.000000            2              176\n",
      "\n",
      "[177 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding scores to new dataframe\n",
    "rankings = pd.DataFrame({\n",
    "    'zipcodes': full_dataset['modzcta'],\n",
    "    'safety_scores': safety_scores,\n",
    "    'livability_scores': livability_scores\n",
    "})\n",
    "\n",
    "# Creating actual rankings for each zipcode\n",
    "rankings['safety_rank'] = rankings['safety_scores'].rank(method='min', ascending=False).astype(int)\n",
    "rankings['livability_rank'] = rankings['livability_scores'].rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "# Saving to rankings.csv\n",
    "rankings.to_csv('rankings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
